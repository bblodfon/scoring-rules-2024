[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Benchmark results analysis",
    "section": "",
    "text": "We benchmark the two versions of the survival brier score (Graf et al. 1999), namely the Integrated Survival Brier Score (ISBS) and the proposed re-weighted version (RISBS) (see documentation details for their respective formulas). The first (ISBS) is not a proper scoring rule (Rindt et al. 2022), the second (RISBS) is (Sonabend et al. 2024). Our goal is to assess whether these scores exhibit differences in simulated and real-world datasets, and if so, to understand the reasons behind these differences.\nLoad libraries:\n\n\nCode\nlibrary(tidyverse)\nlibrary(mlr3proba)\nlibrary(DT)\nlibrary(ggpubr)\nlibrary(ComplexHeatmap)\nlibrary(circlize)"
  },
  {
    "objectID": "index.html#aim",
    "href": "index.html#aim",
    "title": "Benchmark results analysis",
    "section": "",
    "text": "We benchmark the two versions of the survival brier score (Graf et al. 1999), namely the Integrated Survival Brier Score (ISBS) and the proposed re-weighted version (RISBS) (see documentation details for their respective formulas). The first (ISBS) is not a proper scoring rule (Rindt et al. 2022), the second (RISBS) is (Sonabend et al. 2024). Our goal is to assess whether these scores exhibit differences in simulated and real-world datasets, and if so, to understand the reasons behind these differences.\nLoad libraries:\n\n\nCode\nlibrary(tidyverse)\nlibrary(mlr3proba)\nlibrary(DT)\nlibrary(ggpubr)\nlibrary(ComplexHeatmap)\nlibrary(circlize)"
  },
  {
    "objectID": "index.html#simulated-data-results",
    "href": "index.html#simulated-data-results",
    "title": "Benchmark results analysis",
    "section": "Simulated Data Results",
    "text": "Simulated Data Results\n\n\n\n\n\n\nNote\n\n\n\n\nCode to generate the simulated datasets. For directly getting the res.rds object, contact the author via a GitHub issue.\n\nWe simulate datasets with varying characteristics:\n\nIndependent (random) vs dependent censoring\nPH (Proportional Hazards) vs non-PH data (time-varying coefficients)\nProportion of censoring (10\\% - 80\\%)\nNumber of observations (100 - 1000)\n\nThe ‘fixed’ parameters in our simulations are the following:\n\nTime horizon (max event or censoring time): 365 days\nNumber of datasets to generate per (1)-(4) combinations: 100\nNumber of covariates per dataset (chosen randomly): 3-10 (low-dim setting)\n\n\n\n\nIntroduction\nFor each simulated dataset, we performed a simple train/test resampling (70%/30%). Each resampling was stratified using the status variable so that the proportion of censoring remains the same in each respective train and test set.\nWe trained 3 models in each respective train set, namely the Kaplan-Meier, the Cox Proportional Hazards (CoxPH) model and an Accelerated Failure Time (AFT) model with Weibull distribution for the time-to-event output variable. We tested the performance of each model in each respective test set using the ISBS and RISBS measures, integrating up to the 80\\% quantile of the event times of each train set.\nGet the benchmark results:\n\n\nCode\nres = readRDS(file = \"res.rds\")\n\n\n\n\n\n\n\n\nOrganization of Results\n\n\n\nWe will divide the presentation of simulation data results in 4 sub-sections, according to:\n\nWhether the simulated datasets were satisfying the proportional hazards assumption and\nWhether censoring was dependent or not from the survival outcome.\n\n\n\n\n\nProp. Hazards and Independent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_ph_ind = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == TRUE, cens_dep == FALSE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean((km_proper - km_improper)^2)),\n    cox_rmse = sqrt(mean((cox_proper - cox_improper)^2)),\n    aft_rmse = sqrt(mean((aft_proper - aft_improper)^2))\n)\n\nres_ph_ind |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_ph_ind$km_rmse, res_ph_ind$cox_rmse, res_ph_ind$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE,\n        row_names_side = \"left\", row_title = \"#Observations\", col = col_fun)\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nProp. Hazards and Dependent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_ph_dep = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == TRUE, cens_dep == TRUE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean((km_proper - km_improper)^2)),\n    cox_rmse = sqrt(mean((cox_proper - cox_improper)^2)),\n    aft_rmse = sqrt(mean((aft_proper - aft_improper)^2))\n)\n\nres_ph_dep |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_ph_dep$km_rmse, res_ph_dep$cox_rmse, res_ph_dep$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nNon-Prop. Hazards and Independent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_noph_ind = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == FALSE, cens_dep == FALSE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean((km_proper - km_improper)^2)),\n    cox_rmse = sqrt(mean((cox_proper - cox_improper)^2)),\n    aft_rmse = sqrt(mean((aft_proper - aft_improper)^2))\n)\n\nres_noph_ind |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_noph_ind$km_rmse, res_noph_ind$cox_rmse, res_noph_ind$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nNon-Prop. Hazards and Dependent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_noph_dep = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == FALSE, cens_dep == TRUE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean((km_proper - km_improper)^2)),\n    cox_rmse = sqrt(mean((cox_proper - cox_improper)^2)),\n    aft_rmse = sqrt(mean((aft_proper - aft_improper)^2))\n)\n\nres_noph_dep |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_noph_dep$km_rmse, res_noph_dep$cox_rmse, res_noph_dep$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")"
  },
  {
    "objectID": "index.html#real-world-data-results",
    "href": "index.html#real-world-data-results",
    "title": "Benchmark results analysis",
    "section": "Real-world Data Results",
    "text": "Real-world Data Results\n\n\n\n\n\n\nNote\n\n\n\n\nCompressed data files\nR script used to translate the datasets into mlr3 tasks and extract useful info, namely:\n\nn_obs: Number of observations\nn_vars: Number of total variables\nn_factors: Number of factor/categorical variables\nn_numeric: Number of numeric variables\ncens_prop: Proportion of censoring\nadmin_cens_prop: Proportion of censored observations that are censored administratively, i.e. at the last censoring time\ndep_cens_prop: Proportion of significant coefficients (adjusted p &lt; 0.05) to predict censoring status using a logistic regression model\nprop_haz: If the dataset satisfies the proportional hazards assumption (p &gt; 0.05 using the Grambsch-Therneau test (Grambsch and Therneau 1994))\n\nR script used to run the benchmark\n\n\n\n\nIntroduction\nWe used a total of 26 real-word, low-dimensional datasets (fewer features than observations) for benchmarking, some of which are freely available via various R packages. For each dataset, we performed a simple train/test resampling (80%/20%) 100 times. Each resampling was stratified using the status variable so that the proportion of censoring remains the same in each respective train and test set.\nWe trained 3 models in each respective train set, namely the Kaplan-Meier, the Cox Proportional Hazards (CoxPH) model and an Accelerated Failure Time (AFT) model with Weibull distribution for the time-to-event output variable. We tested the performance of each model in each respective test set using the ISBS and RISBS measures, integrating up to the 80\\% quantile of the event times of each train set. We kept also the brier scores for each specific observation (observation-wise scores) in all respective test sets.\n\n\nDatasets table\n\n\nCode\n# task info, see `prepare_tasks.R`\ntask_tbl = readRDS(file = \"task_tbl.rds\")\n\ntask_tbl |&gt; \n  select(-task) |&gt;\n  datatable(\n    rownames = FALSE, \n    options = list(pageLength = 13, searching = TRUE,\n                   order = list(list(0, 'asc')))) |&gt;\n    formatRound(columns = 6:8, digits = 2) |&gt;\n    formatStyle(columns = 'prop_haz',\n                backgroundColor = styleEqual(c(TRUE, FALSE), c(\"#4DAF4A\", \"#E41A1C\")))\n\n\n\n\n\n\n\n\n\nBenchmarking stats\nGet the benchmark results:\n\n\nCode\n# see `run_bench.R`\n# Compressed file: https://github.com/survival-org/scoring-rules-2024/blob/main/bench_res.rds\nbench_res = readRDS(file = \"bench_res.rds\")\n\n\nWe calculate the Pearson correlation and root mean square error (RMSE) between RISBS and ISBS scores per dataset (100 resamplings) and model:\n\n\nCode\nscore_corrs = \n  bench_res |&gt; \n  group_by(task_id) |&gt; \n  select(ends_with(\"proper\")) |&gt; \n  summarize(\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_rmse  = sqrt(mean((km_proper - km_improper)^2)),\n    cox_rmse = sqrt(mean((cox_proper - cox_improper)^2)),\n    aft_rmse = sqrt(mean((aft_proper - aft_improper)^2))\n  ) |&gt; \n  arrange(desc(cox_cor))\n\nscore_corrs |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 13, searching = TRUE, order = list(list(2, 'desc')))\n  ) |&gt;\n  formatRound(columns = 2:7, digits = 3)\n\n\n\n\n\n\n\nMean and standard deviation of the Pearson’s correlation and RMSE across all datasets:\n\n\nCode\nscore_corrs |&gt;\n  summarise(across(-task_id, list(mean = mean, sd = sd))) |&gt; \n  pivot_longer(cols = everything(), \n               names_to = c(\"model\", \"statistic\", \".value\"), \n               names_pattern = \"(.*)_(.*)_(.*)\"\n  ) |&gt;\n  knitr::kable(digits = 3)\n\n\n\n\n\nmodel\nstatistic\nmean\nsd\n\n\n\n\nkm\ncor\n0.967\n0.089\n\n\ncox\ncor\n0.973\n0.039\n\n\naft\ncor\n0.973\n0.039\n\n\nkm\nrmse\n0.007\n0.008\n\n\ncox\nrmse\n0.007\n0.007\n\n\naft\nrmse\n0.007\n0.007\n\n\n\n\n\n\n\nRISBS vs ISBS\nScatter plots of RISBS vs ISBS scores per dataset (100 dots/resamplings per figure). We add the regression line in each plot. Datasets are ordered by decreasing correlation between the two metrics:\n\n\nCode\n# order is by decreasing correlation\nfor (id in score_corrs$task_id) {\n  p = \n    bench_res |&gt;\n    filter(task_id == id) |&gt;\n    select(ends_with(\"proper\")) |&gt;\n    pivot_longer(cols = everything(), names_to = c(\"model\", \".value\"), names_pattern = \"(.*)_(.*)\") |&gt;\n    mutate(model = factor(model, levels = c(\"km\", \"cox\", \"aft\"))) |&gt;\n    # scatter plot with Pearson's coef.\n    ggpubr::ggscatter(\n      x = \"proper\", y = \"improper\",\n      facet.by = c(\"model\"),\n      panel.labs = list(model = c(\"Kaplan-Meier\", \"CoxPH\", \"AFT (Weibull)\")),\n      xlab = \"RISBS (proper)\",\n      ylab = \"ISBS (improper)\",\n      color = \"black\", shape = 21, size = 2,\n      add = \"reg.line\",  # Add regression line\n      add.params = list(color = \"blue\", fill = \"lightgray\"), # Customize regr. line\n      conf.int = TRUE, # Add confidence interval\n      cor.coef = TRUE, # Add Pearson's correlation coefficient\n      cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\")\n    ) +\n    labs(title = id) +\n    theme(panel.spacing = unit(1, \"cm\"))\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRISBS vs ISBS (observation-wise scores)\nScatter plots of RISBS vs ISBS observation-wise scores per dataset. Every figure has a total of dots equal to (100 resamplings) x (number of test observations in each resampling). We draw the reference y = x line in each plot. Datasets are ordered by decreasing proportion of censoring after applying the 80\\% quantile t_max cutoff in each full dataset.\n\n\nCode\ncens_props = vapply(task_tbl$task, function(task) {\n  event_times = task$unique_event_times()\n  t_max = unname(quantile(event_times, probs = 0.8))\n  truth = task$truth()\n  times  = truth[, 1]\n  status = truth[, 2]\n  status_tmax = status[times &lt;= t_max]\n  sum(status_tmax == 0)/length(status_tmax) # censoring proportion\n}, numeric(1))\n\nnames(cens_props) = task_tbl$task_id\n\n\n\n\nCode\nids = names(sort(cens_props, decreasing = TRUE))\n\nfor (id in ids) {\n  p = \n    bench_res |&gt;\n    filter(task_id == id) |&gt;\n    select(ends_with(\"scores\"), test_status) |&gt; # `test_status` is the censoring status for coloring\n    unnest(cols = everything()) |&gt;\n    pivot_longer(cols = ends_with(\"scores\"), names_to = c(\"model\", \"type\", \".value\"), names_pattern = \"(.*)_(.*)_(.*)\") |&gt;\n    pivot_wider(names_from = type, values_from = scores, values_fn = list) |&gt; \n    unnest(cols = everything()) |&gt;\n    rename(Status = test_status) |&gt;\n    mutate(Status = case_when(Status == 0 ~ \"Censored\", TRUE ~ \"Event\")) |&gt;\n    mutate(\n      Status = as.factor(Status),\n      model = factor(model, levels = c(\"km\", \"cox\", \"aft\"))\n    ) |&gt;\n    # scatter plot with Pearson's coef.\n    ggpubr::ggscatter(\n      x = \"proper\", y = \"improper\",\n      facet.by = c(\"model\"),\n      panel.labs = list(model = c(\"Kaplan-Meier\", \"CoxPH\", \"AFT (Weibull)\")),\n      xlab = \"RISBS (proper)\",\n      ylab = \"ISBS (improper)\",\n      color = \"Status\", shape = 21, size = 2, alpha = 0.8,\n      palette = c(\"Censored\" = \"#377eb8\", \"Event\" = \"#e41a1c\"),\n      cor.coef = TRUE, # Add Pearson's correlation coefficient\n      cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\")\n    ) +\n    labs(title = id) +\n    geom_abline(slope = 1, size = 0.8) +\n    theme(panel.spacing = unit(1, \"cm\"))\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that in the 4 last datasets we have censored observations with t &gt; t_{max} so they are excluded from the calculation of the brier scores as we integrate up to the t_max time horizon cutoff. Therefore only observations that have experienced the event contribute to the scores (but the estimation of the censoring distribution using the Kaplan-Meier uses all observations of a train set).\n\n\nFigures for paper\nResults only for the cox model and two datasets:\n\nVETERANNAFLD\n\n\n\n\nCode\n# RISBS vs ISBS\nscores = \n  bench_res |&gt;\n  filter(task_id == \"veteran\") |&gt; \n  select(cox_proper, cox_improper) # 100 resamplings\nRMSE = sqrt(mean((scores$cox_proper - scores$cox_improper)^2))\nmean(abs(scores$cox_proper - scores$cox_improper))\n\n\n[1] 0.006368727\n\n\nCode\nsd(abs(scores$cox_proper - scores$cox_improper))\n\n\n[1] 0.006689354\n\n\nCode\np1 = ggpubr::ggscatter(data = scores, x = \"cox_proper\", y = \"cox_improper\",\n  xlab = \"RISBS (proper)\", ylab = \"ISBS (improper)\",\n  shape = 21, size = 2, alpha = 0.8,\n  add = \"reg.line\",  # Add regression line\n  add.params = list(color = \"blue\", fill = \"lightgray\"), # Customize regr. line\n  conf.int = TRUE, # Add confidence interval\n  cor.coef = TRUE, # Add Pearson's correlation coefficient\n  cor.coef.size = 8,\n  cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\"), \n  ggtheme = theme_classic(base_size = 18)\n) +\nlabs(title = \"VETERAN\") +\ntheme(plot.title = element_text(hjust = 0.5)) +\nannotate(\"text\", size = 8, x = 0.175, y = 0.12, hjust = 0,\n          label = paste0(\"RMSE = \", round(RMSE, digits = 3)))\np1\n\n\n\n\n\nCode\n# ggsave(filename = \"p1.pdf\", width = 7, height = 5)\n\n# per observation scores\nobs_scores = \n  bench_res |&gt;\n  filter(task_id == \"veteran\") |&gt;\n  select(cox_proper_scores, cox_improper_scores, test_status) |&gt; # `test_status` is the censoring status for coloring\n  rename(proper_scores = cox_proper_scores, improper_scores = cox_improper_scores) |&gt;\n  unnest(cols = everything()) |&gt;\n  pivot_longer(cols = ends_with(\"scores\"), names_to = c(\"type\", \".value\"), names_pattern = \"(.*)_(.*)\") |&gt;\n  pivot_wider(names_from = type, values_from = scores, values_fn = list) |&gt; \n  unnest(cols = everything()) |&gt;\n  rename(Status = test_status) |&gt;\n  mutate(Status = as.factor(case_when(Status == 0 ~ \"Censored\", TRUE ~ \"Event\")))\n\n# 18 - 28 test observations after `t_max` cutoff per resampling (28 is 137 * 20%)\nstatus = bench_res |&gt; filter(task_id == \"veteran\") |&gt; pull(test_status)\nmap(status, length) |&gt; unlist() |&gt; summary()\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   21.00   23.00   23.23   25.00   28.00 \n\n\nCode\n# truth: 2143 events, 180 censored\nobs_scores$Status |&gt; table()\n\n\n\nCensored    Event \n     180     2143 \n\n\nCode\nRMSE_all = sqrt(mean((obs_scores$proper - obs_scores$improper)^2))\nRMSE_event = sqrt(mean((\n  obs_scores |&gt; filter(Status == \"Event\") |&gt; pull(proper) - \n  obs_scores |&gt; filter(Status == \"Event\") |&gt; pull(improper))^2))\nRMSE_cens = sqrt(mean((\n  obs_scores |&gt; filter(Status == \"Censored\") |&gt; pull(proper) - \n  obs_scores |&gt; filter(Status == \"Censored\") |&gt; pull(improper))^2))\n\np2 = ggpubr::ggscatter(data = obs_scores, x = \"proper\", y = \"improper\",\n  xlab = \"RISBS (proper)\", ylab = \"ISBS (improper)\",\n  color = \"Status\", shape = 21, size = 3, alpha = 0.8,\n  palette = c(\"Censored\" = \"#377eb8\", \"Event\" = \"#e41a1c\"),\n  cor.coef = TRUE, # Add Pearson's correlation coefficient\n  cor.coef.size = 8,\n  cor.coeff.args = list(method = \"pearson\"),\n  ggtheme = theme_classic(base_size = 18)\n) +\nlabs(title = \"VETERAN\") +\ntheme(legend.position = \"none\") +\ngeom_abline(slope = 1, size = 0.8) +\ntheme(plot.title = element_text(hjust = 0.5)) +\nannotate(\"text\", size = 6, x = 0.35, y = c(0.25, 0.2, 0.15), hjust = 0,\n          label = c(paste0(\"RMSE (all) = \", round(RMSE_all, digits = 3)), \n                    paste0(\"RMSE (Event) = \", round(RMSE_event, digits = 3)),\n                    paste0(\"RMSE (Censored) = \", round(RMSE_cens, digits = 3))))\np2\n\n\n\n\n\nCode\n# ggsave(filename = \"p2.pdf\", width = 7, height = 5)\n\n\n\n\n\n\nCode\n# RISBS vs ISBS\nscores = \n  bench_res |&gt;\n  filter(task_id == \"nafld1\") |&gt; \n  select(cox_proper, cox_improper) # 100 resamplings\nRMSE = sqrt(mean((scores$cox_proper - scores$cox_improper)^2))\nmean(abs(scores$cox_proper - scores$cox_improper))\n\n\n[1] 0.002702623\n\n\nCode\nsd(abs(scores$cox_proper - scores$cox_improper))\n\n\n[1] 0.0008136839\n\n\nCode\np3 = ggpubr::ggscatter(data = scores, x = \"cox_proper\", y = \"cox_improper\",\n  xlab = \"RISBS (proper)\", ylab = \"ISBS (improper)\",\n  shape = 21, size = 2, alpha = 0.8,\n  add = \"reg.line\",  # Add regression line\n  add.params = list(color = \"blue\", fill = \"lightgray\"), # Customize regr. line\n  conf.int = TRUE, # Add confidence interval\n  cor.coef = TRUE, # Add Pearson's correlation coefficient\n  cor.coef.size = 8,\n  cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\"), \n  ggtheme = theme_classic(base_size = 18)\n) +\nlabs(title = \"NAFLD\") +\ntheme(plot.title = element_text(hjust = 0.5)) +\nannotate(\"text\", size = 8, x = 0.044, y = 0.04, hjust = 0,\n          label = paste0(\"RMSE = \", round(RMSE, digits = 3)))\np3\n\n\n\n\n\nCode\n# ggsave(filename = \"p3.pdf\", width = 7, height = 5)\n  \n# per observation scores\nobs_scores = \n  bench_res |&gt;\n  filter(task_id == \"nafld1\") |&gt;\n  select(cox_proper_scores, cox_improper_scores, test_status) |&gt; # `test_status` is the censoring status for coloring\n  rename(proper_scores = cox_proper_scores, improper_scores = cox_improper_scores) |&gt;\n  unnest(cols = everything()) |&gt;\n  pivot_longer(cols = ends_with(\"scores\"), names_to = c(\"type\", \".value\"), names_pattern = \"(.*)_(.*)\") |&gt;\n  pivot_wider(names_from = type, values_from = scores, values_fn = list) |&gt; \n  unnest(cols = everything()) |&gt;\n  rename(Status = test_status) |&gt;\n  mutate(Status = as.factor(case_when(Status == 0 ~ \"Censored\", TRUE ~ \"Event\")))\n\n# 509 - 597 test observations after `t_max` cutoff per resampling (it should \n# have been 800 = 4000 * 20%, so now we got less observations contributing to \n# the scores and given 92% censoring, we know that most of these are censored obs :)\nstatus = bench_res |&gt; filter(task_id == \"nafld1\") |&gt; pull(test_status)\nmap(status, length) |&gt; unlist() |&gt; summary()\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  509.0   541.0   556.5   553.8   566.2   597.0 \n\n\nCode\n# truth: 5181 events, 50194 censored\nobs_scores$Status |&gt; table()\n\n\n\nCensored    Event \n   50194     5181 \n\n\nCode\nRMSE_all = sqrt(mean((obs_scores$proper - obs_scores$improper)^2))\nRMSE_event = sqrt(mean((\n  obs_scores |&gt; filter(Status == \"Event\") |&gt; pull(proper) - \n  obs_scores |&gt; filter(Status == \"Event\") |&gt; pull(improper))^2))\nRMSE_cens = sqrt(mean((\n  obs_scores |&gt; filter(Status == \"Censored\") |&gt; pull(proper) - \n  obs_scores |&gt; filter(Status == \"Censored\") |&gt; pull(improper))^2))\n\np4 = ggpubr::ggscatter(data = obs_scores, x = \"proper\", y = \"improper\",\n  xlab = \"RISBS (proper)\", ylab = \"ISBS (improper)\",\n  color = \"Status\", shape = 21, size = 3, alpha = 0.8,\n  palette = c(\"Censored\" = \"#377eb8\", \"Event\" = \"#e41a1c\"),\n  cor.coef = TRUE, # Add Pearson's correlation coefficient\n  cor.coef.size = 8,\n  cor.coeff.args = list(method = \"pearson\"),\n  ggtheme = theme_classic(base_size = 18)\n) +\nlabs(title = \"NAFLD\") +\ngeom_abline(slope = 1, size = 0.8) +\ntheme(plot.title = element_text(hjust = 0.5)) +\nannotate(\"text\", size = 5, x = 0.4, y = c(0.22, 0.16, 0.10), hjust = 0,\n          label = c(paste0(\"RMSE (all) = \", round(RMSE_all, digits = 3)), \n                    paste0(\"RMSE (Event) = \", round(RMSE_event, digits = 3)),\n                    paste0(\"RMSE (Censored) = \", round(RMSE_cens, digits = 3))))\np4\n\n\n\n\n\nCode\n# ggsave(filename = \"p4.pdf\", width = 7, height = 5)"
  }
]