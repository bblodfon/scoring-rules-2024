[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Benchmark results analysis",
    "section": "",
    "text": "We benchmark the two versions of the survival brier score (Graf et al. 1999), namely the Integrated Survival Brier Score (ISBS) and the proposed we-weighted version (RISBS) (see documentation details for their respective formulas). The first (ISBS) is not a proper scoring rule (Rindt et al. 2022), the second (RISBS) is (Sonabend 2022). Our goal is to assess whether these scores exhibit differences in simulated and real-world datasets, and if so, to understand the reasons behind these differences.\nLoad libraries:\n\n\nCode\nlibrary(tidyverse)\nlibrary(mlr3proba)\nlibrary(DT)\nlibrary(ggpubr)\nlibrary(ComplexHeatmap)\nlibrary(circlize)"
  },
  {
    "objectID": "index.html#aim",
    "href": "index.html#aim",
    "title": "Benchmark results analysis",
    "section": "",
    "text": "We benchmark the two versions of the survival brier score (Graf et al. 1999), namely the Integrated Survival Brier Score (ISBS) and the proposed we-weighted version (RISBS) (see documentation details for their respective formulas). The first (ISBS) is not a proper scoring rule (Rindt et al. 2022), the second (RISBS) is (Sonabend 2022). Our goal is to assess whether these scores exhibit differences in simulated and real-world datasets, and if so, to understand the reasons behind these differences.\nLoad libraries:\n\n\nCode\nlibrary(tidyverse)\nlibrary(mlr3proba)\nlibrary(DT)\nlibrary(ggpubr)\nlibrary(ComplexHeatmap)\nlibrary(circlize)"
  },
  {
    "objectID": "index.html#simulated-data-results",
    "href": "index.html#simulated-data-results",
    "title": "Benchmark results analysis",
    "section": "Simulated Data Results",
    "text": "Simulated Data Results\n\n\n\n\n\n\nNote\n\n\n\n\nCode to generate the simulated datasets. For directly getting the res.rds object, contact the author via a GitHub issue.\n\nWe simulate datasets with varying characteristics:\n\nIndependent (random) vs dependent censoring\nPH (Proportional Hazards) vs non-PH data (time-varying coefficients)\nProportion of censoring (10\\% - 80\\%)\nNumber of observations (100 - 1000)\n\nThe ‘fixed’ parameters in our simulations are the following:\n\nTime horizon (max event or censoring time): 365 days\nNumber of datasets to generate per (1)-(4) combinations: 100\nNumber of covariates per dataset (chosen randomly): 3-10 (low-dim setting)\n\n\n\n\nIntroduction\nFor each simulated dataset, we performed a simple train/test resampling (70%/30%). Each resampling was stratified using the status variable so that the proportion of censoring remains the same in each respective train and test set.\nWe trained 3 models in each respective train set, namely the Kaplan-Meier, the Cox Proportional Hazards (CoxPH) model and an Accelerated Failure Time (AFT) model with Weibull distribution for the time-to-event output variable. We tested the performance of each model in each respective test set using the ISBS and RISBS measures, integrating up to the 80\\% quantile of the event times of each train set.\nGet the benchmark results:\n\n\nCode\nres = readRDS(file = \"res.rds\")\n\n\n\n\n\n\n\n\nOrganization of Results\n\n\n\nWe will divide the presentation of simulation data results in 4 sub-sections, according to:\n\nWhether the simulated datasets were satisfying the proportional hazards assumption and\nWhether censoring was dependent or not from the survival outcome.\n\n\n\n\n\nProp. Hazards and Independent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_ph_ind = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == TRUE, cens_dep == FALSE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean(km_proper - km_improper)^2),\n    cox_rmse = sqrt(mean(cox_proper - cox_improper)^2),\n    aft_rmse = sqrt(mean(aft_proper - aft_improper)^2),\n)\n\nres_ph_ind |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_ph_ind$km_rmse, res_ph_ind$cox_rmse, res_ph_ind$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE,\n        row_names_side = \"left\", row_title = \"#Observations\", col = col_fun)\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_ph_ind |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nProp. Hazards and Dependent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_ph_dep = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == TRUE, cens_dep == TRUE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean(km_proper - km_improper)^2),\n    cox_rmse = sqrt(mean(cox_proper - cox_improper)^2),\n    aft_rmse = sqrt(mean(aft_proper - aft_improper)^2),\n)\n\nres_ph_dep |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_ph_dep$km_rmse, res_ph_dep$cox_rmse, res_ph_dep$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_ph_dep |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nNon-Prop. Hazards and Independent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_noph_ind = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == FALSE, cens_dep == FALSE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean(km_proper - km_improper)^2),\n    cox_rmse = sqrt(mean(cox_proper - cox_improper)^2),\n    aft_rmse = sqrt(mean(aft_proper - aft_improper)^2),\n)\n\nres_noph_ind |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_noph_ind$km_rmse, res_noph_ind$cox_rmse, res_noph_ind$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_noph_ind |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\n\nNon-Prop. Hazards and Dependent Censoring\nFor each combo of number of observations (n_obs) and proportion of censoring (cens_prop) variables (100 simulated datasets per combo), we calculate the following summary stats between RISBS and ISBS: Pearson correlation, mean absolute difference and its standard deviation, root mean square error (RMSE):\n\n\nCode\nres_noph_dep = \n  res |&gt; \n  drop_na() |&gt; # exclude few datasets where AFT prediction didn't work\n  filter(prop_haz == FALSE, cens_dep == TRUE) |&gt;\n  group_by(n_obs, cens_prop) |&gt;\n  summarize(\n    .groups = \"drop\",\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_diff_mean  = mean(abs(km_proper - km_improper)),\n    cox_diff_mean = mean(abs(cox_proper - cox_improper)),\n    aft_diff_mean = mean(abs(aft_proper - aft_improper)),\n    km_diff_sd    = sd(abs(km_proper - km_improper)),\n    cox_diff_sd   = sd(abs(cox_proper - cox_improper)),\n    aft_diff_sd   = sd(abs(aft_proper - aft_improper)),\n    km_rmse  = sqrt(mean(km_proper - km_improper)^2),\n    cox_rmse = sqrt(mean(cox_proper - cox_improper)^2),\n    aft_rmse = sqrt(mean(aft_proper - aft_improper)^2),\n)\n\nres_noph_dep |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 10, searching = TRUE)) |&gt;\n  formatRound(columns = 2:14, digits = c(1, rep(2,3), rep(3,9)))\n\n\n\n\n\n\n\nVisualizing the RMSE between RISBS and ISBS:\n\nCoxAFTKaplan-Meier\n\n\n\n\nCode\ncox_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, cox_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = cox_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\n# color function\nmax_val = round(max(c(res_noph_dep$km_rmse, res_noph_dep$cox_rmse, res_noph_dep$aft_rmse)), digits = 3) + 0.001\ncol_fun = circlize::colorRamp2(c(0, max_val/2, max_val), c(\"#e0f3db\", \"#a8ddb5\", \"#43a2ca\"))\n\nHeatmap(cox_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\naft_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, aft_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = aft_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(aft_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")\n\n\n\n\n\n\n\n\n\nCode\nkm_mat = \n  res_noph_dep |&gt; \n  select(n_obs, cens_prop, km_rmse) |&gt; \n  pivot_wider(names_from = cens_prop, values_from = km_rmse) |&gt; \n  arrange(desc(n_obs)) |&gt;\n  column_to_rownames(var = \"n_obs\") |&gt; \n  as.matrix()\n\nHeatmap(km_mat, name = \"RMSE\", cluster_rows = FALSE, cluster_columns = FALSE,\n        column_title = \"Censoring Proportion\", column_title_side = \"bottom\",\n        column_labels = paste0(seq(from = 10, to = 80, by = 10), \"%\"),\n        column_names_rot = 0, column_names_centered = TRUE, col = col_fun,\n        row_names_side = \"left\", row_title = \"#Observations\")"
  },
  {
    "objectID": "index.html#real-world-data-results",
    "href": "index.html#real-world-data-results",
    "title": "Benchmark results analysis",
    "section": "Real-world Data Results",
    "text": "Real-world Data Results\n\n\n\n\n\n\nNote\n\n\n\n\nCompressed data files\nR script used to translate the datasets into mlr3 tasks and extract useful info, namely:\n\nn_obs: Number of observations\nn_vars: Number of total variables\nn_factors: Number of factor/categorical variables\nn_numeric: Number of numeric variables\ncens_prop: Proportion of censoring\nadmin_cens_prop: Proportion of censored observations that are censored administratively, i.e. at the last censoring time\ndep_cens_prop: Proportion of significant coefficients (adjusted p &lt; 0.05) to predict censoring status using a logistic regression model\nprop_haz: If the dataset satisfies the proportional hazards assumption (p &gt; 0.05 using a global Schoenfeld test)\n\nR script used to run the benchmark\n\n\n\n\nIntroduction\nWe used a total of 26 real-word, low-dimensional datasets (fewer features than observations) for benchmarking, some of which are freely available via various R packages. For each dataset, we performed a simple train/test resampling (80%/20%) 100 times. Each resampling was stratified using the status variable so that the proportion of censoring remains the same in each respective train and test set.\nWe trained 3 models in each respective train set, namely the Kaplan-Meier, the Cox Proportional Hazards (CoxPH) model and an Accelerated Failure Time (AFT) model with Weibull distribution for the time-to-event output variable. We tested the performance of each model in each respective test set using the ISBS and RISBS measures, integrating up to the 80\\% quantile of the event times of each train set. We kept also the brier scores for each specific observation (per-observation scores) in all respective test sets.\n\n\nDatasets table\n\n\nCode\n# task info, see `prepare_tasks.R`\ntask_tbl = readRDS(file = \"task_tbl.rds\")\n\ntask_tbl |&gt; \n  select(-task) |&gt;\n  datatable(\n    rownames = FALSE, \n    options = list(pageLength = 13, searching = TRUE,\n                   order = list(list(0, 'asc')))) |&gt;\n    formatRound(columns = 6:8, digits = 2) |&gt;\n    formatStyle(columns = 'prop_haz',\n                backgroundColor = styleEqual(c(TRUE, FALSE), c(\"#4DAF4A\", \"#E41A1C\")))\n\n\n\n\n\n\n\n\n\nBenchmarking stats\nGet the benchmark results:\n\n\nCode\n# see `run_bench.R`\n# Compressed file: https://github.com/bblodfon/scoring-rules-2024/blob/main/bench_res.rds\nbench_res = readRDS(file = \"bench_res.rds\")\n\n\nWe calculate the Pearson correlation and root mean square error (RMSE) between RISBS and ISBS scores per dataset (100 resamplings) and model:\n\n\nCode\nscore_corrs = \n  bench_res |&gt; \n  group_by(task_id) |&gt; \n  select(ends_with(\"proper\")) |&gt; \n  summarize(\n    km_cor  = cor(km_proper, km_improper),\n    cox_cor = cor(cox_proper, cox_improper),\n    aft_cor = cor(aft_proper, aft_improper),\n    km_rmse  = sqrt(mean(km_proper - km_improper)^2),\n    cox_rmse = sqrt(mean(cox_proper - cox_improper)^2),\n    aft_rmse = sqrt(mean(aft_proper - aft_improper)^2),\n  ) |&gt; \n  arrange(desc(cox_cor))\n\nscore_corrs |&gt;\n  datatable(\n    rownames = FALSE,\n    options = list(pageLength = 13, searching = TRUE, order = list(list(2, 'desc')))\n  ) |&gt;\n  formatRound(columns = 2:7, digits = 3)\n\n\n\n\n\n\n\nMean and standard deviation of the Pearson’s correlation and RMSE across all datasets:\n\n\nCode\nscore_corrs |&gt;\n  summarise(across(-task_id, list(mean = mean, sd = sd))) |&gt; \n  pivot_longer(cols = everything(), \n               names_to = c(\"model\", \"statistic\", \".value\"), \n               names_pattern = \"(.*)_(.*)_(.*)\"\n  ) |&gt;\n  knitr::kable(digits = 3)\n\n\n\n\n\nmodel\nstatistic\nmean\nsd\n\n\n\n\nkm\ncor\n0.967\n0.089\n\n\ncox\ncor\n0.973\n0.039\n\n\naft\ncor\n0.973\n0.039\n\n\nkm\nrmse\n0.007\n0.008\n\n\ncox\nrmse\n0.006\n0.007\n\n\naft\nrmse\n0.006\n0.006\n\n\n\n\n\n\n\nRISBS vs ISBS\nScatter plots of RISBS vs ISBS scores per dataset (100 dots/resamplings per figure). Datasets are ordered by decreasing correlation between the two metrics:\n\n\nCode\n# order is by decreasing correlation\nfor (id in score_corrs$task_id) {\n  p = \n    bench_res |&gt;\n    filter(task_id == id) |&gt;\n    select(ends_with(\"proper\")) |&gt;\n    pivot_longer(cols = everything(), names_to = c(\"model\", \".value\"), names_pattern = \"(.*)_(.*)\") |&gt;\n    mutate(model = factor(model, levels = c(\"km\", \"cox\", \"aft\"))) |&gt;\n    # scatter plot with Pearson's coef.\n    ggpubr::ggscatter(\n      x = \"proper\", y = \"improper\",\n      facet.by = c(\"model\"),\n      panel.labs = list(model = c(\"Kaplan-Meier\", \"CoxPH\", \"AFT (Weibull)\")),\n      xlab = \"RISBS (proper)\",\n      ylab = \"ISBS (improper)\",\n      color = \"black\", shape = 21, size = 2,\n      add = \"reg.line\",  # Add regression line\n      add.params = list(color = \"blue\", fill = \"lightgray\"), # Customize regr. line\n      conf.int = TRUE, # Add confidence interval\n      cor.coef = TRUE, # Add Pearson's correlation coefficient\n      cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\")\n    ) +\n    labs(title = id) +\n    theme(panel.spacing = unit(1, \"cm\"))\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRISBS vs ISBS (per-observation scores)\nScatter plots of RISBS vs ISBS per-observation scores per dataset. Every figure has a total of dots equal to (100 resamplings) x (number of test observations in each resampling). Datasets are ordered by decreasing proportion of censoring after applying the 80\\% quantile t_max cutoff in each full dataset.\n\n\nCode\ncens_props = vapply(task_tbl$task, function(task) {\n  event_times = task$unique_event_times()\n  t_max = unname(quantile(event_times, probs = 0.8))\n  truth = task$truth()\n  times  = truth[, 1]\n  status = truth[, 2]\n  status_tmax = status[times &lt;= t_max]\n  sum(status_tmax == 0)/length(status_tmax) # censoring proportion\n}, numeric(1))\n\nnames(cens_props) = task_tbl$task_id\n\n\n\n\nCode\nids = names(sort(cens_props, decreasing = TRUE))\n\nfor (id in ids) {\n  p = \n    bench_res |&gt;\n    filter(task_id == id) |&gt;\n    select(ends_with(\"scores\"), test_status) |&gt; # `test_status` is the censoring status for coloring\n    unnest(cols = everything()) |&gt;\n    pivot_longer(cols = ends_with(\"scores\"), names_to = c(\"model\", \"type\", \".value\"), names_pattern = \"(.*)_(.*)_(.*)\") |&gt;\n    pivot_wider(names_from = type, values_from = scores, values_fn = list) |&gt; \n    unnest(cols = everything()) |&gt;\n    rename(Status = test_status) |&gt;\n    mutate(Status = case_when(Status == 0 ~ \"Censored\", TRUE ~ \"Event\")) |&gt;\n    mutate(\n      Status = as.factor(Status),\n      model = factor(model, levels = c(\"km\", \"cox\", \"aft\"))\n    ) |&gt;\n    # scatter plot with Pearson's coef.\n    ggpubr::ggscatter(\n      x = \"proper\", y = \"improper\",\n      facet.by = c(\"model\"),\n      panel.labs = list(model = c(\"Kaplan-Meier\", \"CoxPH\", \"AFT (Weibull)\")),\n      xlab = \"RISBS (proper)\",\n      ylab = \"ISBS (improper)\",\n      color = \"Status\", shape = 21, size = 2, alpha = 0.8,\n      palette = c(\"Censored\" = \"#377eb8\", \"Event\" = \"#e41a1c\"),\n      add = \"reg.line\",  # Add regression line\n      add.params = list(color = \"blue\", fill = \"lightgray\"), # Customize regr. line\n      conf.int = TRUE, # Add confidence interval\n      cor.coef = TRUE, # Add Pearson's correlation coefficient\n      cor.coeff.args = list(method = \"pearson\", label.sep = \"\\n\")\n    ) +\n    labs(title = id) +\n    theme(panel.spacing = unit(1, \"cm\"))\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that in the 4 last datasets we have censored observations with t &gt; t_{max} so they are excluded from the calculation of the brier scores as we integrate up to the t_max time horizon cutoff. Therefore only observations that have experienced the event contribute to the scores (but the estimation of the censoring distribution using the Kaplan-Meier uses all observations of a train set)."
  },
  {
    "objectID": "index.html#investigate-inflation-of-proper-isbs",
    "href": "index.html#investigate-inflation-of-proper-isbs",
    "title": "Benchmark results analysis",
    "section": "Investigate inflation of proper ISBS",
    "text": "Investigate inflation of proper ISBS\n\n\n\n\n\n\nNote\n\n\n\nIn this section we investigate an example where the proper ISBS gets inflated (i.e. too large value for the score, compared to the improper version) and show how we can avoid such a thing from happening when evaluating model performance.\n\n\nLet’s use a dataset where in a particular train/test resampling the issue occurs:\n\n\nCode\ninflated_data = readRDS(file = \"inflated_data.rds\")\ntask = inflated_data$task\npart = inflated_data$part\n\ntask\n\n\n&lt;TaskSurv:mgus&gt; (176 x 9)\n* Target: time, status\n* Properties: -\n* Features (7):\n  - dbl (6): age, alb, creat, dxyr, hgb, mspike\n  - fct (1): sex\n\n\nSeparate train and test data:\n\n\nCode\ntask_train = task$clone()$filter(rows = part$train)\ntask_test  = task$clone()$filter(rows = part$test)\n\n\nKaplan-Meier of the training survival data:\n\n\nCode\nautoplot(task_train) +\n  labs(title = \"Kaplan-Meier (train data)\",\n       subtitle = \"Time-to-event distribution\")\n\n\n\n\n\nKaplan-Meier of the training censoring data:\n\n\nCode\nautoplot(task_train, reverse = TRUE) +\n    labs(title = \"Kaplan-Meier (train data)\",\n         subtitle = \"Censoring distribution\")\n\n\n\n\n\nEstimates of the censoring distribution G_{KM}(t) (values from the above figure):\n\n\nCode\nkm_train = task_train$kaplan(reverse = TRUE)\nkm_tbl = tibble(time = km_train$time, surv = km_train$surv)\ntail(km_tbl)\n\n\n# A tibble: 6 × 2\n   time  surv\n  &lt;dbl&gt; &lt;dbl&gt;\n1 12140 0.75 \n2 12313 0.625\n3 12319 0.5  \n4 12349 0.25 \n5 12689 0.125\n6 13019 0    \n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs we can see from the above figures and table, due to having at least one censored observation at the last time point, G_{KM}(t_{max}) = 0 for t_{max} = 13019.\n\n\nIs there an observation on the test set that has died (status = 1) on that last time point (or after)?\n\n\nCode\nmax_time = max(km_tbl$time) # max time point\n\ntest_times  = task_test$times()\ntest_status = task_test$status()\n\n# get the id of the observation in the test data\nid = which(test_times &gt;= max_time & test_status == 1)\nid\n\n\n[1] 14\n\n\nYes there is such observation!\nIn mlr3proba using proper = TRUE for the RISBS calculation, this observation will be weighted by 1/0 according to the formula. Practically, to avoid division by zero, a small value eps = 0.001 will be used.\nLet’s train a simple Cox model on the train set and calculate its predictions on the test set:\n\n\nCode\ncox = lrn(\"surv.coxph\")\np = cox$train(task, part$train)$predict(task, part$test)\n\n\nWe calculate the ISBS (improper) and RISBS (proper) scores:\n\n\nCode\ngraf_improper = msr(\"surv.graf\", proper = FALSE, id = \"graf.improper\")\ngraf_proper   = msr(\"surv.graf\", proper = TRUE,  id = \"graf.proper\")\np$score(graf_improper, task = task, train_set = part$train)\n\n\ngraf.improper \n    0.1493429 \n\n\nCode\np$score(graf_proper, task = task, train_set = part$train)\n\n\ngraf.proper \n   10.64584 \n\n\nAs we can see there is huge difference between the two versions of the score. We check the per-observation scores (integrated across all time points):\nObservation-wise RISBS scores:\n\n\nCode\ngraf_proper$scores\n\n\n [1]   0.08994417   0.02854219   0.04214266   0.15578719   0.05364692\n [6]   0.12969150   0.06463256   0.32033549   2.43262450   0.11602432\n[11]   0.03228501   0.10172088   0.14652850 367.10227335   0.18004727\n[16]   0.21991511   0.09070024   0.03507389   0.19856844   0.07925747\n[21]   0.07732517   0.06982001   0.19468406   0.05267402   0.02419841\n[26]   0.17645640   0.07633691   0.04379196   0.07839955   0.06684222\n[31]   0.05457688   0.02874430   0.04071108   0.00000000   0.00000000\n\n\nObservation-wise ISBS scores:\n\n\nCode\ngraf_improper$scores\n\n\n [1] 0.08994417 0.02854219 0.04214266 0.15578719 0.05364692 0.12969150\n [7] 0.06463256 0.32033549 0.62971109 0.11602432 0.03228501 0.10172088\n[13] 0.14652850 1.07969258 0.16743979 0.21991511 0.09070024 0.03507389\n[19] 0.19856844 0.07925747 0.07732517 0.06982001 0.19468406 0.05267402\n[25] 0.02419841 0.16199516 0.07633691 0.04379196 0.07839955 0.06684222\n[31] 0.05457688 0.02874430 0.04071108 0.03512466 0.46541333\n\n\nIt is the one observation that we identified earlier that causes the inflation of the RISBS score - it’s pretty much an outlier compared to all other values:\n\n\nCode\ngraf_proper$scores[id]\n\n\n[1] 367.1023\n\n\nBy setting t_max (time horizon to evaluate the measure up to) to the 95\\% quantile of the event times, we can solve the inflation problem of the proper RISBS score, since we will divide by a value larger than zero from the above table of G_{KM}(t) values. The t_max time point is:\n\n\nCode\nt_max = as.integer(quantile(task_train$unique_event_times(), 0.95))\nt_max\n\n\n[1] 10080\n\n\nIntegrating up to t_max, the proper RISBS score is:\n\n\nCode\ngraf_proper_tmax = msr(\"surv.graf\", id = \"graf.proper\", proper = TRUE, t_max = t_max)\np$score(graf_proper_tmax, task = task, train_set = part$train) # ISBS\n\n\ngraf.proper \n  0.1436484 \n\n\nThe score for the specific observation that had experienced the event at (or beyond) the latest training time point is now:\n\n\nCode\ngraf_proper_tmax$scores[id]\n\n\n[1] 0.141502\n\n\n\n\n\n\n\n\nSuggestion when calculating time-integrated scoring rules\n\n\n\nTo avoid the inflation of RISBS and generally have a more robust estimation of both RISBS and ISBS scoring rules, we advise to set the t_max argument (time horizon). This can be either study-driven or based on a meaningful quantile of the distribution of (usually event) times in your dataset (e.g. 80\\%)."
  }
]